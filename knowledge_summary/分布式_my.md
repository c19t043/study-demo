# 分布式

## 为什么要进行系统拆分

## 如何进行系统拆分

## 你们如何解决分布式事务问题的

## XA的一致性如何保证

## TCC如果出现网络连不通怎么办

## 集群部署时的分布式session如何实现

## 如果让你写一个消息队列，该如何进行架构设计啊？说一下你的思路

## 在项目中缓存是如何使用的

## 缓存如果使用不当会造成什么后果

## 在集群模式下，redis的key是如何寻址的

## 分布式寻址都有哪些算法

## 了解一致性hash算法吗

## 如何动态增加和删除一个节点？

## 了解什么是redis的雪崩和穿透

## redis崩溃之后会怎么样？系统该如何应对这种情况？

## 如何处理redis的穿透？

## 如何保证缓存与数据库的双写一致性？

## redis的并发竞争问题是什么？如何解决这个问题？

## 了解Redis事务的CAS方案吗？

## 生产环境中的redis是怎么部署的？

## 为什么要分库分表（设计高并发系统的时候，数据库层面该如何设计）？

## 用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？

## 你们具体是如何对数据库如何进行垂直拆分或水平拆分的？

## 现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表动态切换到分库分表上？

## 如何设计可以动态扩容缩容的分库分表方案？

## 分库分表之后，id主键如何处理？

## 如何实现mysql的读写分离？

## MySQL主从复制原理的是啥？

## 如何解决mysql主从同步的延时问题？

## 如何设计一个高可用系统？

## 比如说equals和hashcode是啥关系？string类为啥是final的？

## 说一下你们在项目里是怎么用消息队列的？

在项目订单系统中，有这么个业务场景，就是用户购买服务后，需要短信提示用户服务购买成功。
比如说门诊业务，用户预约18年9月1日下午2点的儿童门诊，如果用户下单预约成功，那么就会短信提示用户预约成功这个时间点的儿童门诊等等

## 那你们为什么使用消息队列啊？

在不使用消息队列之前，系统中发送短信时，都是通过Get请求调用远程短信功能
在用户下单成功后，同步发送短信。但在实际环境中，多次发生短信发送超时，导致用户钱扣了，但没下单成功，或用户下单成功，但用户没有收到短信
所以将短信相关业务独立部署，业务系统通过消息中间件来发送相关业务短信

## 消息队列都有什么优点和缺点？

+ 优点：解耦，异步，消峰
+ 缺点
    1. 系统整体可用性下降：比如有ABC三个系统，在原有架构中，系统A只需要直接调用系统BC，就可以了，现在引入外部依赖，系统A不直接调用系统BC，
        而是通过消息中间件关联系统BC，如果消息中间件挂了，那么系统BC就不可用了，系统整体可以性降低了
    2. 系统复杂度提高：为了提高系统整体可用性，就要确保消息中间件处于可用状态，那么就要考虑如何保证消息中间件的高可用性，如何处理消息丢失问题，
        如何保证消息传递的有序性，如何保证消息没有被重复消费等等问题
    3. 要处理系统数据的一致性问题：比如系统A将消息发送MQ之后，就返回成功，那么就默认认为系统BC执行成功，但是系统BC执行失败了，怎么处理

## 既然你用了MQ，可能是某一种MQ，那么你当时做没做过调研，各消息中间件的优缺点？

市面上比较流行的消息中间件有activemq,rabbitmq,rocketmq,kafka，在系统重构前，对这几款消息中间件做个大致了解下
就吞吐量，时效性，可用性，消息可靠性，功能支持这5个方面做了下比较
就吞吐量而言，activemq,rabbitmq，支持上万的吞吐量，而rocketmq，kafka支持上10万的吞吐量
就时效性而言，activemq,rabbitmq,rocketmq,kafka都是在ms级以内，rabbitmq时效性最好，延迟最低
就可用性而言，activemq,rabbitmq是基于主从实现的高可用，而rocketmq,kafka是基于分布式架构实现的高可用，分布式架构相对于主从架构，可用性更高
就消息可靠性而言，activemq存在丢失数据的可能，而rabbitmq，rocketmq，kafka经过配置，可以做到消息0丢失
就功能支持而言，activemq，rabbitmq,rocketmq对MQ功能支持较为完善，而kafka支持基本mq功能
总而言之，activemq因为社区不活跃，版本迭代慢，不推荐使用
rabbitmq,社区比较活跃，版本迭代快，性能极好，延时很低，但是基于erlang语言开发的，国内深入研究的人比较少
rocketmq，社区活跃一般，可用性和消息可靠性非常好，在阿里有大规模应用，但是是阿里开源项目，社区有突然黄掉的风险
对于中小型公司而言，技术实力较为一般，技术挑战不是特别高，用rabbitmq就能满足一般需求
对于大型公司而言，基础架构研发能力强，用rocketmq是很好的选择
如果是大数据领域的实时计算，日志采集等领域，kafka是业内的标准，apache 顶级开源项目，社区活跃度很高，基本可不能黄掉

## 你们公司为什么选择使用kafka

公司未来核心业务支柱，儿童健康大数据，将是公司下一步的发展重心，同时团队计划做日志采集，系统异常实时报告等相关业务，所以决定使用kafka作为消息中间件
而解耦订单短信相关的业务，直接基于kafka来做，就不再引入其他消息中间价，提高系统复杂度

## 如何保证消息队列的高可用

项目中使用的消息中间件是kafka，kafka是基于分布式架构实现的高可用，kafka集群由多个broker节点组成，一个broker就是一台机器
一个topic可以有多个partition,每个partition存放部分数据，每个partition可以分布在不同broker节点上，
每个partition可以有多个副本，每个副本可以分布在不同broker节点上
如果某个broker宕机了，这个broker上的partition在其他broker上还有副本，
如果副本的leader节点在宕机的broker上，重新选举出leader节点，就可以继续向外提供服务

## 如何保证消息不被重复消费（如何保证消费的时候是幂等的）

在kafka中，生产者每生成一条消息到一个partition中，都会分配一个唯一key，offset,消费者消费partition中的消息，
消费完成后，需要将对应Offset提交到kakfa中，如果消费者处理完这条消息，但是在向kafka提交叫offset之前就宕机了
重启kafka之后，再次消费这个消息时存在重复消费的可能
在项目中，我们结合redis来解决消息重复消费的问题，消费者每消费一条消息，就将这条消息的partition与offset组成可以存放到redis集群中
在kafka宕机重启后，先判断redis中是否存在对应key，如果不存在，才消费这条消息

## 如何保证消息的可靠性传输？要是消息丢失了怎么办啊

要保证在使用kafka时消息不丢失，至少要从三个方面解决

1. 在kafka服务端，搭建kafka集群，保证kafka处于高可用状态，然后在创建topic时要设置分区副本数，一台kafka服务挂了，在其他的kafka服务上有这台kafka服务的数据副本，并设置最小同步副本数必须大于1，否则拒绝提供写入
2. 在producer端，数据一定要发送到kafka服务上，配置ack=all，和最大重试次数,如果多次重试失败，将消息保存到本地，或其他地方，由人工处理这些消息
3. 在consumer端，关闭offset自动提交，在处理完消息后，手动提交，并且保证消息不被重复消费

## 如何保证消息的顺序性

在kafka中,producer将消息发送到kafka服务中，根据消息进入partition的先后顺序，分配有序的offset，在consumer中，将消费同一个topic的consumer分在同一个消费者组，其中一个消费者对应一个partition，consumer按顺序消费消息即可

## 如何解决消息队列的延时以及过期失效问题

+ 在大量请求积压在消息队列中，而以kafka消费者单线程消费速度，可能需要几个小时，或更多时间才能消费完毕，我们可以采用消费者多线程消费消息，或者创建新的topic，将这个topic的partition设置为原topic的多倍，临时修改原有消费者消费逻辑，将原有topic中消息分发到新的topic中，并临时扩充消费者，订阅新得topic，多线程消费消息，直到积压消息消费完毕，再重新恢复到原有逻辑
+ 如果消息中间件设置了消息过期时间，在消费积压消息过程中，有消息过期，这需要在访问低峰时，手动将未消费的过期消息，查找出来，手动导入到消息队列，再次消费

## 消息队列满了以后该怎么处理

需要临时修改消费者逻辑，将消息丢弃，快速消费消息，等在访问低峰时，将未处理的消息重新查出来，手动导入到消息队列中，重新消费

## 有几百万消息持续积压几小时，说说怎么解决

在大量请求积压在消息队列中，而以kafka消费者单线程消费速度，可能需要几个小时，或更多时间才能消费完毕，我们可以采用消费者多线程消费消息，或者创建新的topic，将这个topic的partition设置为原topic的多倍，临时修改原有消费者消费逻辑，将原有topic中消息分发到新的topic中，并临时扩充消费者，订阅新得topic，多线程消费消息，直到积压消息消费完毕，再重新恢复到原有逻辑

## 如果让你写一个消息队列，该如何进行架构设计？说一下你的思路

设计一个消息队列要考虑这几个要素，首先要保证消息0丢失，保证消息可以顺序读写，其次要考虑消息是否要做持久化，最后要考虑消息队列的可用性，可伸缩性
可以参考kafka,
在kafka中，通过producer和服务端配置，可以保证消息0丢失，而kafka中partition中消息是有序的，可以保证消息的有序性
kafka将消息持久化到磁盘，通过建立索引文件和磁盘顺序读写，来提高消息持久化性能
kafka时基于以分布式的架构设计，和分区副本来保证消息队列的可用性，而通过增加topic的分区数来做到快速扩容

## 在项目中缓存是如何使用的？

## 为啥在项目里要用缓存呢？

## 用了缓存之后会有啥不良的后果？

## redis和memcached有啥区别

+ redis支持丰富的数据结构和复杂的数据操作，memcached只支持kv存取
+ redis支持集群模式，memcached没有原生的集群模式，需要依赖客户端分片写入

## redis的线程模型

redis是基于reactor开发的网络事件处理器，这个处理器叫做文件事件处理器，文件事件处理器是单线程模式运行的，因此redis才叫做单线程的模型
文件事件处理器包括socket，IO多路复用程序，文件事件派发器，事件处理器
当socket变得可读时，将产生AE_READABLE事件
当socket变得可写时，将产生AE_WRITABLE事件
IO多路服用程序监听多个socket,将监听的socket放入到一个队列中，每次从队列中取出一个socket给事件派发器
事件派发器根据socket产生的事件选择对应的事件处理器来处理
当一个socket的事件处理完成后，IO多路服用程序才会从队列中取出下一个socket给事件派发器

## 客户端与redis一次通信流程

在redis启动初始化时，会将redis的连接应答处理器跟AE_READABLE事件关联起来
当一个客户端发起连接时，会产生AE_READABLE事件，然后由应答处理器来跟客户端建立连接，创建客户端对应socket
同时将这个socket的AE_READABLE事件跟命令请求处理器关联起来
当客户端向redis发起请求时，在socket上会产生AE_READABLE事件，然后由对应的事件处理器来处理，这个命令请求处理器会从socket中读取请求相关数据，执行相关处理
接着redis端准备好了给给客户端响应的相关数据之后，将socket的AE_WRITABLE事件跟命令回复处理器关联
当客户端准备好读取数据时，在socket上会产生AE_WRITABLE事件，由对应的命令回复处理器来处理，将准备好的数据返回写入socket，供客户端读取
当命令回复处理器处理完毕，删除这个socket与命令回复处理器之间的关联关系

## 为啥redis单线程模型也能效率这么高？

+ redis是纯内存操作
+ 其核心是基于非阻塞的IO多路复用机制
+ 并且redis的单线程避免了多线程频繁上线文切换问题

## 多线程频繁上下文切换问题

线程在执行任务时，需要CPU分时间片给线程，当线程在这个时间片内没有执行完任务时，在执行下一个线程时，需要缓存上个线程的执行环境相关数据
当之前未执行玩的线程再次分配到时间片执行任务时，需要重建线程之前的执行环境继续执行下去
在多线程频繁切换执行相关任务时，需要多次缓存重建线程执行环境，将消耗更多的系统资源

## redis都有哪些数据类型？分别在哪些场景下使用比较合适？

redis有5种数据类型字符串(String),hash,列表（list）,集合(set)，有序集合（sorted set）
其中
字符串是最基础的类型，可以做简单的kv存取
hash可以用来存放一些结构化数据，比如对象，当对象中某个属性发生变化时，只需要修改对应的对应的某个值就可以了
有序列表可以实现很多复杂的功能，比如粉丝列表，简单的消息队列，分页查询等
无序集合，集合中没有重复数据，可以完成集合的交集，并集，差集操作，比如获取查找两个人的共同好友
有序集合，拥有无序集合的所有操作，并且集合中的数据可以排序，根据集合中数据的分数，可以完成很多复杂的功能，比如销售排行榜

## redis的过期策略都有哪些

+ 定期删除 >> redis默认每隔100ms就随机抽取一些过期时间的key，检查其是否过期，如果过期就删除
+ 惰性删除 >> 在定期删除的策略下，可能还存在很多已过期未删除的数据，在获取某个key时，先检查这个key是否过期，如果过期就删除，然后返回nil
+ 内存淘汰机制 >> 在定期删除和惰性删除策略下，可能还存在很多已过期未删除的数据，当内存不足以容纳新数据时，将执行内存淘汰机制，清除一些key，腾出内存空间

## 内存淘汰机制都有哪些

+ no-eviction >> 当内存不足以容纳新数据时，新写入数据会报错
+ allkeys-LRU >> 当内存不足以容纳新数据时，在键空间中，移除最近最少使用的key
+ allkeys-random >> 当内存不足以容纳新数据时，在键空间中，随机移除某个key
+ volatile-LRU >> 当内存不足以容纳新数据时，在设置了过期时间的键空间中，移除最近最少使用的key
+ volatile-random >> 当内存不足以容纳新数据时，在设置了过期时间的键空间中，随机移除某个key
+ volatile-ttl >> 当内存不足以容纳新数据时，有更早过期时间的key优先移除

## 手写一下LRU代码实现

```java
public class LRUCache<K, V> extends LinkedHashMap<K, V> {
    private final int CACHE_SIZE;

    // 这里就是传递进来最多能缓存多少数据
    public LRUCache(int cacheSize) {
        // 这块就是设置一个hashmap的初始大小，同时最后一个true指的是让linkedhashmap按照访问顺序来进行排序，最近访问的放在头，最老访问的就在尾
        super((int) Math.ceil(cacheSize / 0.75) + 1, 0.75f, true);
        CACHE_SIZE = cacheSize;
    }

    @Override
    protected boolean removeEldestEntry(Map.Entry eldest) {
        return size() > CACHE_SIZE; // 这个意思就是说当map中的数据量大于指定的缓存个数的时候，就自动删除最老的数据
    }
}
```

## 怎么保障redis的高可用性

redis有两种高可用策略：一种是redis主从+哨兵模式；另一种是redis集群模式
先说redis主从+哨兵模式：通过redis配置可以实现一主多从，主节点提供写服务，从节点提供读服务，哨兵节点监控主从节点，
当主节点宕机了，哨兵节点会从从节点中，选举一个作为新的主节点，其他从节点重新连接主节点，然后继续对外提供服务
redis本身支持集群模式，主节点对外提供读写服务,每个主节点都可以有从节点，从节点作为主节点的备份，不对外提供服务，
当主节点宕机，超半数集群主节点选举一个从节点切换为主节点

## redis的主从复制原理能介绍一下么？

当一个slave启动时，会向master节点发送psync指令
如果slave是重新连接，那么master会向slave进行增量复制
如果salve是第一连接，那么master会向slave进行一次全量复制

当进行全量复制时，master会fork一个子进程，生成一份rdb快照文件，同时master会缓存从fork子进程后接受到所有写指令
当rdb快照文件生成完毕，master会将快照文件发送给slave，slave会向数据文件写到本地磁盘，然后加载到内存中，
当数据加载完毕，master会将后序缓存的所有写指令发送给slave节点，slave节点也会同步这些写指令

## redis的哨兵原理能介绍一下么？

哨兵本身是分布式的，以集群模式运行，互相协同工作，
哨兵监控主从节点，当一个哨兵发现某个节点宕机了，这个节点状态设置为主观宕机，并通知其他哨兵节点
当达到法定人数的哨兵节点都判断这个节点为客观宕机时，这个节点状态设置为客观宕机，并同步消息给其他哨兵
当宕机的节点为主节点时，会选出一个哨兵，从从节点中选举出一个从节点切换为主节点，哨兵在修改从节点配置，重新连接主节点，主从节点继续对外提供服务

## redis的持久化有哪几种方式？

redis支持两种数据持久化机制，rdb和aof
其中rdb持久化机制，会间隔一定时间，根据redis当前内存数据生成一份快照文件
而aof会将接受到的所有写指令追加到一份叫appendonly.aof文件中

## 不同的持久化机制都有什么优缺点？

首先说rdb持久化机制的优缺点
rdb持久化机制的优点
1）rdb快照文件适合做冷备
2）在执行rdb快照时，对redis性能影响较小
3）相较于aof，基于rdb快照文件来重新构建内存数据时，更加快速
rdb持久化机制的缺点
1）相较于aof，基于rdb快照文件恢复数据，会丢失更多数据
2）当内存数据过大时，在执行rdb操作，对系统性能影响较大

aof持久化机制的优点
1）相交于rdb，aof持久化机制更能保护数据不丢失
aof持久化机制的缺点
1）相较于rdb，基于aof文件恢复内存数据，速度慢

## 持久化机制具体底层是如何实现的？

+ rdb持久化机制：当内存数据变更满足一定条件时，redis主进程会fork一个子进程，然后根据子进程当前内存数据，生成一份rdb快照文件
+ aof持久化机制：会将所有写指令，通过append-only模式，先将数据写入os-cache中，然后间隔一定时间发送fsync指令，将数据追加到文件中

## redis集群模式的工作原理能说一下么？

## 在集群模式下，redis的key是如何寻址的？

## 分布式寻址都有哪些算法？

## 了解一致性hash算法吗？

## 了解什么是redis的雪崩和穿透？

+ 缓存穿透：访问一个不存在的key,缓存不起作用，请求发送到数据库层，当并发访问量大时，大量请求发送到数据库层，造层数据库压力过大，数据库直接挂掉
> 解决方案
> 采用布隆过滤器，使用一个足够大的bitmap，用于存储可能访问的key，不存在的key直接被过滤；
> 访问key未在DB查询到值，也将空值写进缓存，但可以设置较短过期时间。
+ 缓存击穿：一个存在的key，在缓存过期的那一刻，有大量并发请求，这些请求发送到数据库层，造成数据库压力过大，数据库直接挂掉
> 解决方案
> 在访问key之前，采用SETNX（set if not exists）来设置另一个短期key来锁住当前key的访问，访问结束再删除该短期key。
+ 缓存雪崩：同一时刻大量缓存失效，在并发访问量大时，大量请求发送到数据库层，造成数据库压力过大，数据库直接挂掉
> 解决方案
> 可以给缓存设置过期时间时加上一个随机值时间，使得每个key的过期时间分布开来，不会集中在同一时刻失效。

## redis崩溃之后会怎么样？系统该如何应对这种情况？

## 如何处理redis的穿透？

## 如何保证缓存与数据库的双写一致性？

## redis的并发竞争问题是什么？如何解决这个问题？

## 了解Redis事务的CAS方案吗？

## 生产环境中的redis是怎么部署的？

## 为什么要进行系统拆分？

## 如何进行系统拆分？

## 拆分后不用dubbo可以吗？

## 分布式服务接口的幂等性如何设计（比如不能重复扣款）？

## 分布式服务接口请求的顺序性如何保证？

同过一致性hash算法，将同一资源的请求分发到同一服务中，在服务内部经过hash取模，将同一资源的请求分发到同一个内存队列中，单线程依次执行队列中的请求

## 如何自己设计一个类似dubbo的rpc框架？

## zk都有哪些使用场景？

1. 分布式服务协调
2. 分布式锁
3. HA高可用性
4. 元数据，或配置信息管理

## 一般实现分布式锁都有哪些方式？

+ zk分布式锁
+ redis分布式锁

## 使用redis如何设计分布式锁？

+ 创建一个有过期时间的key，如果key创建成功，就获取到了锁，失败，就是没有获取到锁，如果任务执行完毕，就删除这个key，释放锁
+ redlock算法

## 使用zk来设计分布式锁可以吗？

+ 尝试创建一个临时节点，如果创建成功，就获取到了锁，失败，就没有没有获取到锁，当任务执行完毕，就删除这个节点，释放锁

## 这两种分布式锁的实现方式哪种效率比较高？

+ redis分布式锁,需要自己不断去尝试获取锁，比较消耗性能
+ zk分布式锁，如果获取不到锁，就注册一个监听器，不需要不断尝试获取锁，性能开销较小

## 集群部署时的分布式session如何实现？

## 分布式事务了解吗？

## 你们如何解决分布式事务问题的？

## 如何设计一个高并发系统？

## 为什么要分库分表（设计高并发系统的时候，数据库层面该如何设计）？

## 用过哪些分库分表中间件？

## 不同的分库分表中间件都有什么优点和缺点？

## 你们具体是如何对数据库如何进行垂直拆分或水平拆分的？

## 现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表动态切换到分库分表上？

## 如何设计可以动态扩容缩容的分库分表方案？

## 分库分表之后，id主键如何处理？

## 你们有没有做MySQL读写分离？

## 如何实现mysql的读写分离？

## MySQL主从复制原理的是啥？

## 如何解决mysql主从同步的延时问题？

## 如何设计一个高可用系统？

## 如何限流？在工作中是怎么做的？说一下具体的实现？

在hystrix框架中，通过资源隔离,每个依赖服务都有资源池，资源使用上限来达到限流的目的;
其中资源隔离有两种实现方式：线程池和信号量
在日常情况下，我们使用线程池技术实现资源隔离，因为我们关心依赖服务的调用和访问的超时问题
而像系统内部，不需要关心超时问题的调用，我们可以使用信号量技术实现资源隔离

## 如何进行熔断？熔断框架都有哪些？具体实现原理知道吗？

目前我只知道有Hystrix框架可以进行熔断措施
在项目中使用Hystrix框架实现服务熔断，当hystrix熔断机制检查到短时间内依赖服务调用多次超时或失败，hystrix框架会将请求快速失败，走降级机制
断路器的工作原理：
hystrix会将每一个依赖服务调用成功，失败，超时等事件发送给断路器，
断路器会对成功，失败，超时等的词素进行统计，断路器会根据这些次数来决定是否开启短路
如果打开了断路器，那么在一段时间内会，对依赖服务的调用会直接短路，走降级机制
在一段时间之后，会断路器处于半开状态，这时尝试调用一次服务，如果调用成功，断路器关闭，如果依然调用失败，断路器依旧开启

## 如何进行降级？

在项目中使用hystrix可以实现服务降级，当依赖调用失败或超时，hystrix框架会自动调用配置好的降级方法

## 什么是限流，熔断，降级，资源隔离，运营监控？

限流：系统涌入大量超过服务支持的并发请求，导致系统崩溃，为提供系统的可用性，对涌入的大量并发请求做限制，服务只处理能力范围内的请求
熔断：依赖服务短时间内多次出现服务不可用问题，当再次访问这个依赖服务时，直接拒绝访问
降级：因为某些原因可能导致系统崩溃，或出现大面积服务不可用的情况，为了提高系统的可用性，临时舍去部分不关键的功能，或采取应急方案，保障系统能正常访问
资源隔离：对系统资源做限制，防止因为某些意外情况导致系统资源耗尽而出现服务不可用
运营监控：对系统运行环境和某些服务指标进行监控，当出现异常情况时，做报警